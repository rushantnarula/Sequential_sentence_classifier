{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_chars(text):\n",
    "    return \" \".join(list(text))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "labels = ['OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS','BACKGROUND']\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "abstract1 = input()\n",
    "nlp = English() \n",
    "sentencizer = nlp.create_pipe(\"sentencizer\") \n",
    "nlp.add_pipe('sentencizer') \n",
    "doc = nlp(abstract1) \n",
    "abstract_lines = [str(sent) for sent in list(doc.sents)]\n",
    "total_lines_in_sample = len(abstract_lines)\n",
    "sample_lines = []\n",
    "for i, line in enumerate(abstract_lines):\n",
    "    sample_dict = {}\n",
    "    sample_dict[\"text\"] = str(line)\n",
    "    sample_dict[\"line_number\"] = i\n",
    "    sample_dict[\"total_lines\"] = total_lines_in_sample - 1\n",
    "    sample_lines.append(sample_dict)\n",
    "test_abstract_line_numbers = [line[\"line_number\"] for line in sample_lines]\n",
    "test_abstract_line_numbers_one_hot = tf.one_hot(test_abstract_line_numbers, depth=15) \n",
    "test_abstract_total_lines = [line[\"total_lines\"] for line in sample_lines]\n",
    "test_abstract_total_lines_one_hot = tf.one_hot(test_abstract_total_lines, depth=20)\n",
    "abstract_chars = [split_chars(sentence) for sentence in abstract_lines]\n",
    "test_abstract_pred_probs = loaded_model.predict(x=(test_abstract_line_numbers_one_hot,\n",
    "                                                   test_abstract_total_lines_one_hot,\n",
    "                                                   tf.constant(abstract_lines),\n",
    "                                                   tf.constant(abstract_chars)))\n",
    "test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n",
    "test_abstract_pred_classes = [label_encoder.classes_[i] for i in test_abstract_preds]\n",
    "o = ''\n",
    "m = ''\n",
    "r = ''\n",
    "c = ''\n",
    "b = ''\n",
    "for i, line in enumerate(abstract_lines):\n",
    "    if(test_abstract_pred_classes[i]) == 'OBJECTIVE':\n",
    "        o = o + line + ' '\n",
    "    elif(test_abstract_pred_classes[i]) == 'METHODS':\n",
    "        m = m + line + ' '\n",
    "    elif(test_abstract_pred_classes[i]) == 'RESULTS':\n",
    "        r = r + line + ' '\n",
    "    elif(test_abstract_pred_classes[i]) == 'CONCLUSIONS':\n",
    "        c = c + line + ' '\n",
    "    elif(test_abstract_pred_classes[i]) == 'BACKGROUND':\n",
    "        b = b + line + ' '\n",
    "if(len(o)) > 0:\n",
    "    print('OBJECTIVE:',o)\n",
    "if(len(m)) > 0:\n",
    "    print('METHODS:',m)\n",
    "if(len(r)) > 0:\n",
    "    print('RESULTS:',r)\n",
    "if(len(c)) > 0:\n",
    "    print('CONCLUSIONS:',c)\n",
    "if(len(b)) > 0:\n",
    "    print('BACKGROUND:',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"skimlit_tribrid_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
