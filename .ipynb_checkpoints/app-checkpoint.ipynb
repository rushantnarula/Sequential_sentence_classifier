{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for skimlit_tribrid_model/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1b93ea1fb3d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"skimlit_tribrid_model/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[1;32m    939\u001b[0m                             ckpt_options, options, filters)\n\u001b[1;32m    940\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         raise FileNotFoundError(\n\u001b[0m\u001b[1;32m    942\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n You may be trying to load on a different device \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0;34m\"from the computational device. Consider setting the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for skimlit_tribrid_model/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"skimlit_tribrid_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__, template_folder='templates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "@app.route('/index')\n",
    "def index():\n",
    "    return render_template('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_chars(text):\n",
    "    return \" \".join(list(text))\n",
    "\n",
    "def predictor(data):\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = ['OBJECTIVE', 'METHODS', 'RESULTS', 'CONCLUSIONS','BACKGROUND']\n",
    "    labels = label_encoder.fit_transform(labels)\n",
    "    abstract1 = data\n",
    "    nlp = English() \n",
    "    sentencizer = nlp.create_pipe(\"sentencizer\") \n",
    "    nlp.add_pipe('sentencizer') \n",
    "    doc = nlp(abstract1) \n",
    "    abstract_lines = [str(sent) for sent in list(doc.sents)]\n",
    "    total_lines_in_sample = len(abstract_lines)\n",
    "    sample_lines = []\n",
    "    for i, line in enumerate(abstract_lines):\n",
    "        sample_dict = {}\n",
    "        sample_dict[\"text\"] = str(line)\n",
    "        sample_dict[\"line_number\"] = i\n",
    "        sample_dict[\"total_lines\"] = total_lines_in_sample - 1\n",
    "        sample_lines.append(sample_dict)\n",
    "    test_abstract_line_numbers = [line[\"line_number\"] for line in sample_lines]\n",
    "    test_abstract_line_numbers_one_hot = tf.one_hot(test_abstract_line_numbers, depth=15) \n",
    "    test_abstract_total_lines = [line[\"total_lines\"] for line in sample_lines]\n",
    "    test_abstract_total_lines_one_hot = tf.one_hot(test_abstract_total_lines, depth=20)\n",
    "    abstract_chars = [split_chars(sentence) for sentence in abstract_lines]\n",
    "    test_abstract_pred_probs = loaded_model.predict(x=(test_abstract_line_numbers_one_hot,\n",
    "                                                   test_abstract_total_lines_one_hot,\n",
    "                                                   tf.constant(abstract_lines),\n",
    "                                                   tf.constant(abstract_chars)))\n",
    "    test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n",
    "    test_abstract_pred_classes = [label_encoder.classes_[i] for i in test_abstract_preds]\n",
    "    o = ''\n",
    "    m = ''\n",
    "    r = ''\n",
    "    c = ''\n",
    "    b = ''\n",
    "    for i, line in enumerate(abstract_lines):\n",
    "        if(test_abstract_pred_classes[i]) == 'OBJECTIVE':\n",
    "            o = o + line + ' '\n",
    "        elif(test_abstract_pred_classes[i]) == 'METHODS':\n",
    "            m = m + line + ' '\n",
    "        elif(test_abstract_pred_classes[i]) == 'RESULTS':\n",
    "            r = r + line + ' '\n",
    "        elif(test_abstract_pred_classes[i]) == 'CONCLUSIONS':\n",
    "            c = c + line + ' '\n",
    "        elif(test_abstract_pred_classes[i]) == 'BACKGROUND':\n",
    "            b = b + line + ' '\n",
    "    if(len(o)) > 0:\n",
    "        o = 'OBJECTIVE: '+ o\n",
    "    if(len(m)) > 0:\n",
    "        m='METHODS: '+m\n",
    "    if(len(r)) > 0:\n",
    "        r='RESULTS: '+r\n",
    "    if(len(c)) > 0:\n",
    "        c='CONCLUSIONS: '+c\n",
    "    if(len(b)) > 0:\n",
    "        b='BACKGROUND: '+b \n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/result', methods = ['POST', 'GET'])\n",
    "def result():\n",
    "    string2 = request.form[\"paragraph_text\"]\n",
    "    prediction = predictor(string2)\n",
    "    return render_template('result.html',prediction = prediction)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This RCT examined the efficacy of a manualized social intervention for children with HFASDs. Participants were randomly assigned to treatment or wait-list conditions. Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language. A response-cost program was applied to reduce problem behaviors and foster skills acquisition. Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures). Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents. High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity. Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
